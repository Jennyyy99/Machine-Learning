{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1669313421078,"sparkVersion":"3.1.3","uid":"Tokenizer_df96a9e31ec7","paramMap":{"outputCol":"token_text","inputCol":"text"},"defaultParamMap":{"outputCol":"Tokenizer_df96a9e31ec7__output"}}
